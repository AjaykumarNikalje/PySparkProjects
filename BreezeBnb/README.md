# ğŸ§  **BreezeBnB Data Engineering Project**

A modular **PySpark project** built using **Poetry** for dependency management and packaging.  
This project demonstrates data ingestion, transformation, and reporting pipelines for Airbnb analytics.

---

## ğŸ—ï¸ **Project Structure**

```
BreezeBnb/
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml              # Poetry project configuration
â”œâ”€â”€ poetry.lock                 # Poetry dependency lock file
â”œâ”€â”€ dist/                       # Generated build artifacts (.whl, .tar.gz)
â”‚   â””â”€â”€ breezebnb-0.1.0-py3-none-any.whl
â”œâ”€â”€ src/
â”‚   â””â”€â”€ breezebnb/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config/             # Configuration and constants
â”‚       â”œâ”€â”€ data_access/        # Readers/Writers for data sources
â”‚       â”œâ”€â”€ reporting/          # Reporting and analytics modules
â”‚       â”œâ”€â”€ resources/          # Static resources or lookup files
â”‚       â”œâ”€â”€ transformations/    # Spark transformation logic
â”‚       â””â”€â”€ utils/              # Logging, config loader, helpers
â”‚
â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.yaml             # Job configuration
â”‚   â”œâ”€â”€ run_airbnb_metrics.py   # ETL job for Airbnb metrics
â”‚   â””â”€â”€ run_analytics.py        # Analytics aggregation job
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_data_reader_integration.py
â”‚   â”‚   â”œâ”€â”€ test_data_writer_integration.py
â”‚   â”‚   â””â”€â”€ test_logger_integration.py
â”‚   â”œâ”€â”€ test_airbnb_transformations.py
â”‚   â””â”€â”€ test_analytics_reporter.py
â”‚
â””â”€â”€ myenv/                      # Poetry-created virtual environment (optional local venv)
```

---

## âš™ï¸ **1ï¸âƒ£ Create and Initialize the Project**

### Step 1 â€” Create the project folder
```bash
mkdir BreezeBnb
cd BreezeBnb

#Create Env
python3.11 -m venv myenv
source myenv/bin/activate
```





### Step 2 â€” Initialize Poetry
#If poetry is not installed, please install poetry first.
```bash
poetry init
```

Follow the prompts to define:
- Name: `breezebnb`
- Version: `0.1.0`
- Description: â€œA PySpark analytics project for Airbnb metrics.â€
- License: â€œMITâ€ (or any)
- Dependencies: add none for now.

---

## ğŸ§© **2ï¸âƒ£ Install Dependencies**
#If you are using existing folders then simply execute below command. This installs all dependencies mentioned in .toml file.
```bash
poetry install
```

### Add core dependencies:
#If you are installing dependencies one by one. This will add dependencies into the .toml file.
```bash
poetry add pyspark pyyaml
```


---

## ğŸ§± **3ï¸âƒ£ Create the Source Folder Structure**

Poetry expects your package source under `src/`.  
So create:
```bash
mkdir -p src/breezebnb/{utils,reporting,transformations,data_access,config,resources}
touch src/breezebnb/__init__.py
```

Then create your **job scripts** (outside the package):
```bash
mkdir jobs
touch jobs/__init__.py
touch jobs/run_airbnb_metrics.py
touch jobs/run_analytics.py
```

Add your configuration file:
```bash
touch jobs/config.yaml
```

---

## ğŸ§° **4ï¸âƒ£ Activate the Poetry Environment**

```bash
poetry shell
```

To confirm:
```bash
which python
```
It should point inside your Poetry virtualenv.

---

## ğŸ§ª **5ï¸âƒ£ Run Unit Tests**

```bash
pytest -v
```

If your imports fail, make sure your test runner is aware of the `src/` path:
```bash
PYTHONPATH=src pytest -v
```

---

## ğŸ“¦ **6ï¸âƒ£ Build the Project (Create Wheel)**

Once everything is working:
```bash
poetry build
```

This will create:
```
dist/
â”œâ”€â”€ breezebnb-0.1.0-py3-none-any.whl
â”œâ”€â”€ breezebnb-0.1.0.tar.gz
```

These are your **deployable artifacts** â€” ready for `spark-submit`.

---

## ğŸš€ **7ï¸âƒ£ Run with Python**

You can now use `python` to execute your job.

From the **project root**:
```bash
python -m jobs.run_airbnb_metrics 2025-01 adhoc /Users/ajaykumarnikalje/Desktop/UKStudyProjects/PythonCode/BreezeBnb_Ver1_Test/PySparkProjects/BreezeBnb/jobs/config.yaml
```

---


```bash
python -m jobs.run_analytics 2025-01 ALL /Users/ajaykumarnikalje/Desktop/UKStudyProjects/PythonCode/BreezeBnb_Ver1_Test/PySparkProjects/BreezeBnb/jobs/config.yaml 5
```

---

## ğŸ“˜ **1ï¸âƒ£ Useful Poetry Commands**

| Task | Command |
|------|----------|
| Install dependencies | `poetry install` |
| Add new dependency | `poetry add package-name` |
| Build project | `poetry build` |
| Run script inside env | `poetry run python jobs/run_analytics.py` |
| Open shell | `poetry shell` |
| Show dependency tree | `poetry show --tree` |
| Check venv path | `poetry env info --path` |

---

## ğŸš€ **12ï¸âƒ£ Example Full Flow**

```bash
# 1. Activate Poetry
poetry shell

# 2. Run tests
pytest -v

# 3. Build the wheel
poetry build

# 4. Run job with Spark

#Create one new folder "Testing" and add whl file dist/breezebnb-0.1.0-py3-none-any.whl and jobs folder. 
#Under Testing folder , run below commands.
spark-submit \
  --master "local[*]" \
  --py-files breezebnb-0.1.0-py3-none-any.whl \
  jobs/run_airbnb_metrics.py \
  2025-01 adhoc jobs/config.yaml

spark-submit \
  --master "local[*]" \
  --py-files breezebnb-0.1.0-py3-none-any.whl \
  jobs/run_analytics.py \
  2025-01 ALL jobs/config.yaml 10
```

---

## ğŸ§­ **15ï¸âƒ£ Summary**

| Step | Description |
|------|--------------|
| 1ï¸âƒ£ | Create Poetry project with `src/` structure |
| 2ï¸âƒ£ | Add dependencies (`pyspark`, `pytest`, etc.) |
| 3ï¸âƒ£ | Build wheel with `poetry build` |
| 4ï¸âƒ£ | Run Spark job with `spark-submit -m breezebnb.jobs.run_analytics` |
| 5ï¸âƒ£ | Keep code modular (`utils/`, `transformations/`, `reporting/`) |
| 6ï¸âƒ£ | Test using `pytest` and clean with `.gitignore` |

